{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Uni\\pwr-pdzb\\vagrant\\sprawozdania\\akwizycja\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import docker\n",
    "import json\n",
    "import opendatasets as od"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:41:35.730359Z",
     "end_time": "2023-04-23T12:41:35.762725Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:41:37.548418Z",
     "end_time": "2023-04-23T12:41:37.582316Z"
    }
   },
   "outputs": [],
   "source": [
    "client = docker.from_env()\n",
    "container = client.containers.get('master')\n",
    "\n",
    "def hdfs_mkdir(path):\n",
    "    container.exec_run(f\"hdfs dfs -mkdir -p /{path}/\")\n",
    "\n",
    "def hdfs_upload(path):\n",
    "    directory = \"/\".join(path.split(\"/\")[:-1])\n",
    "    hdfs_mkdir(directory)\n",
    "    cmd = f\"hdfs dfs -put /data/master_volume/{path} /{directory}\"\n",
    "    print(cmd)\n",
    "    code, output = container.exec_run(cmd)\n",
    "    print(f\"exit code {code}\")\n",
    "    print(output)\n",
    "\n",
    "def hdfs_set_replication_level(number):\n",
    "    container.exec_run(f\"hdfs dfs -setrep -R {number} /\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensure `kaggle.json` is located in the root of the repository or at `~/.kaggle/kaggle.json`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "output_dir = \"../../master_volume/datasets\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:42:01.739906Z",
     "end_time": "2023-04-23T12:42:01.755541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset steam-dataset already exists, skipping download\n",
      "Dataset youtube-trending-video-dataset already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(f\"{output_dir}/steam-dataset\"):\n",
    "    od.download(\"https://www.kaggle.com/datasets/souyama/steam-dataset\", f\"{output_dir}\")\n",
    "else:\n",
    "    print(\"Dataset steam-dataset already exists, skipping download\")\n",
    "\n",
    "if not os.path.isdir(f\"{output_dir}/youtube-trending-video-dataset\"):\n",
    "    od.download(\"https://www.kaggle.com/datasets/rsrishav/youtube-trending-video-dataset\", f\"{output_dir}\")\n",
    "else:\n",
    "    print(\"Dataset youtube-trending-video-dataset already exists, skipping download\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:42:05.522809Z",
     "end_time": "2023-04-23T12:42:05.534496Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset covid-dataset already exists, skipping download\n",
      "covid-dataset.csv: 77.76MB\n"
     ]
    }
   ],
   "source": [
    "path = f\"{output_dir}/covid-dataset.csv\"\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    print(f\"Downloading covid-dataset to {path}\")\n",
    "    r = requests.get(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\", allow_redirects=True)\n",
    "    with open(path, 'wb') as file:\n",
    "        file.write(r.content)\n",
    "else:\n",
    "    print(\"Dataset covid-dataset already exists, skipping download\")\n",
    "\n",
    "print(f\"covid-dataset.csv: {os.stat(path).st_size / (1024 * 1024):.02f}MB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:42:10.207948Z",
     "end_time": "2023-04-23T12:42:10.223587Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting JSON to JSONL\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting JSON to JSONL\")\n",
    "for root, directories, files in os.walk(f\"{output_dir}\"):\n",
    "        for filename in files:\n",
    "            path = os.path.join(root,filename)\n",
    "            output_path = f\"{path}l\"\n",
    "\n",
    "            if os.path.isfile(output_path):\n",
    "                continue\n",
    "\n",
    "            if path.endswith(\".json\"):\n",
    "                print(path)\n",
    "                with open(path, \"r\") as file:\n",
    "                    data = json.load(file)\n",
    "                    if type(data) is dict:\n",
    "                        data = [{\"key\": key, \"value\": data[key]} for key in data]\n",
    "\n",
    "                    with open(output_path, \"w\") as jsonl_file:\n",
    "                        for obj in data:\n",
    "                            json.dump(obj, jsonl_file)\n",
    "                            jsonl_file.write(\"\\n\")\n",
    "                    print(output_path)\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:42:59.162844Z",
     "end_time": "2023-04-23T12:42:59.178869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to HDFS\n",
      "datasets/covid-dataset.csv\n",
      "datasets/steam-dataset/steam_dataset/appinfo/dlc_data/missing.jsonl\n",
      "datasets/steam-dataset/steam_dataset/appinfo/dlc_data/steam_dlc_data.jsonl\n",
      "datasets/steam-dataset/steam_dataset/appinfo/dlc_data/timestamp.txt\n",
      "datasets/steam-dataset/steam_dataset/appinfo/store_data/steam_store_data.jsonl\n",
      "datasets/steam-dataset/steam_dataset/appinfo/store_data/timestamp.txt\n",
      "datasets/steam-dataset/steam_dataset/news_data/missing.jsonl\n",
      "datasets/steam-dataset/steam_dataset/news_data/steam_news_data.jsonl\n",
      "datasets/steam-dataset/steam_dataset/news_data/timestamp.txt\n",
      "datasets/steam-dataset/steam_dataset/steamspy/basic/steam_spy_scrap.jsonl\n",
      "datasets/steam-dataset/steam_dataset/steamspy/basic/timestamp.txt\n",
      "datasets/steam-dataset/steam_dataset/steamspy/detailed/steam_spy_detailed.jsonl\n",
      "datasets/steam-dataset/steam_dataset/steamspy/detailed/timestamp.txt\n",
      "datasets/steam-dataset/steam_dataset/steam_charts/missing.jsonl\n",
      "datasets/steam-dataset/steam_dataset/steam_charts/steam_charts.jsonl\n",
      "datasets/steam-dataset/steam_dataset/steam_charts/timestamp.txt\n",
      "datasets/youtube-trending-video-dataset/BR_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/BR_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/CA_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/CA_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/DE_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/DE_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/FR_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/FR_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/GB_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/GB_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/IN_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/IN_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/JP_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/JP_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/KR_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/KR_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/MX_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/MX_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/RU_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/RU_youtube_trending_data.csv\n",
      "datasets/youtube-trending-video-dataset/US_category_id.jsonl\n",
      "datasets/youtube-trending-video-dataset/US_youtube_trending_data.csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading to HDFS\")\n",
    "for root, directories, files in os.walk(f\"{output_dir}\"):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                continue # skip JSON files, we have JSONL from previous step\n",
    "            path = os.path\\\n",
    "                .join(root,filename)\\\n",
    "                .removeprefix(\"../../master_volume/\")\\\n",
    "                .replace(\"\\\\\", \"/\")\n",
    "\n",
    "            hdfs_upload(path)\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:43:31.174676Z",
     "end_time": "2023-04-23T12:43:31.190297Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "hdfs_set_replication_level(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T12:00:55.251739Z",
     "end_time": "2023-04-23T12:00:56.718692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
