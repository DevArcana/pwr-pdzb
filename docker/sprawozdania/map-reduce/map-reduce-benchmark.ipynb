{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c345704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import uuid\n",
    "import paramiko\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "import requests\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class HadoopRunResult:\n",
    "    name: str\n",
    "    output_path: str\n",
    "    stdout: list[str]\n",
    "    stderr: list[str]\n",
    "    elapsed: str\n",
    "        \n",
    "@dataclass\n",
    "class MultiRunResult:\n",
    "    name: str\n",
    "    results: list[HadoopRunResult]\n",
    "    average: float\n",
    "    output_path: str\n",
    "        \n",
    "    @staticmethod\n",
    "    def fromResults(results: list[HadoopRunResult]):\n",
    "        avg = statistics.mean(list(map(lambda x: int(x.elapsed), results)))\n",
    "        return MultiRunResult(results[0].name, results, avg, results[0].output_path)\n",
    "    \n",
    "def run_n(f, n):\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        results.append(f())\n",
    "    return results\n",
    "        \n",
    "def get_elapsed_time(res):\n",
    "    def get_id_from_res(res):\n",
    "        for line in res[1]:\n",
    "            m = re.search('job_([0-9_]*)', line)\n",
    "            if m != None and m.group(1) != '':\n",
    "                return m.group(1)\n",
    "        return None\n",
    "    x = requests.get(f'http://resourcemanager:8088/ws/v1/cluster/apps/application_{get_id_from_res(res)}')\n",
    "    return x.json()['app']['elapsedTime']\n",
    "\n",
    "def run_in_master(command):\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.connect(\"namenode\", username=\"root\", password=\"pass\")\n",
    "    ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(f\"cd /app/ && . env_var.sh && {command}\")\n",
    "    return (ssh_stdout.readlines(), ssh_stderr.readlines())\n",
    "\n",
    "def get_data_from_output_path(path):\n",
    "    return f\"{path}/merged.txt\"\n",
    "\n",
    "def print_hdfs_output(path):\n",
    "    raw = run_in_master(f\"hdfs dfs -cat {get_data_from_output_path(path)}\")[0]\n",
    "    print(\"\\n\".join(raw[0:1000]))\n",
    "\n",
    "def merge_results(path):\n",
    "    run_in_master(f\"hdfs dfs -cat {path}/part-r-* | hdfs dfs -put - {path}/merged.txt\")\n",
    "    \n",
    "    \n",
    "def convert_results(all_results: list[MultiRunResult])-> pd.DataFrame:\n",
    "    def convert_single_result(multirun_res: MultiRunResult) -> list[int]:\n",
    "        return [res.elapsed for res in multirun_res.results] + [multirun_res.average]\n",
    "    \n",
    "    runs = len(all_results[0].results)\n",
    "    labels = list(map(lambda x: f\"run_{x} (ms)\", range(runs))) + ['average (ms)']\n",
    "    indexes = []\n",
    "    converted_results = []\n",
    "    for multirun_res in all_results:\n",
    "        indexes.append(multirun_res.name)\n",
    "        converted_results.append(convert_single_result(multirun_res))\n",
    "\n",
    "    return pd.DataFrame(np.array(converted_results), columns = labels, index=indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5deddb",
   "metadata": {},
   "source": [
    "# Wp≈Çyw replikacji danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77545de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_covid_01():\n",
    "    covid_01_jar_path = \"/data/master_volume/map_reduce_jars/covid_01.jar\"\n",
    "    covid_01_input_path = \"/datasets/covid-dataset.jsonl\"\n",
    "    covid_01_output_path = \"/out_covid_1\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {covid_01_jar_path} {covid_01_input_path} {covid_01_output_path}\")\n",
    "    merge_results(covid_01_output_path)\n",
    "    return HadoopRunResult(\"Covid01\", covid_01_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d94ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_covid_02(covid_01_output_path):\n",
    "    covid_02_jar_path = \"/data/master_volume/map_reduce_jars/covid_02.jar\"\n",
    "    covid_02_input_path = get_data_from_output_path(covid_01_output_path)\n",
    "    covid_02_output_path = \"/out_covid_2\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {covid_02_jar_path} {covid_02_input_path} {covid_02_output_path}\")\n",
    "    merge_results(covid_02_output_path)\n",
    "    return HadoopRunResult(\"Covid02\",covid_02_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386161ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_covid_03(covid_01_output_path):\n",
    "    covid_03_jar_path = \"/data/master_volume/map_reduce_jars/covid_03.jar\"\n",
    "    covid_03_input_path = get_data_from_output_path(covid_01_output_path)\n",
    "    covid_03_output_path = \"/out_covid_3\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {covid_03_jar_path} {covid_03_input_path} {covid_03_output_path}\")\n",
    "    merge_results(covid_03_output_path)\n",
    "    return HadoopRunResult(\"Covid03\",covid_03_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de38c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steam_01():\n",
    "    steam_01_jar_path = \"/data/master_volume/map_reduce_jars/steam_01_combine.jar\"\n",
    "    steam_01_input_path = \"/datasets/steam-dataset/steam_dataset/appinfo/store_data/steam_store_data.jsonl\"\n",
    "    steam_01_input_path2 = \"/datasets/steam-dataset/steam_dataset/steamspy/basic/steam_spy_scrap.jsonl\"\n",
    "    steam_01_output_path = \"/out_steam_1\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {steam_01_jar_path} {steam_01_input_path} {steam_01_input_path2} {steam_01_output_path}\")\n",
    "    merge_results(steam_01_output_path)\n",
    "    return HadoopRunResult(\"Steam01\",steam_01_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98e5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steam_02(steam_01_output_path):\n",
    "    steam_02_jar_path = \"/data/master_volume/map_reduce_jars/steam_02_choose.jar\"\n",
    "    steam_02_input_path = get_data_from_output_path(steam_01_output_path)\n",
    "    steam_02_output_path = \"/out_steam_2\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {steam_02_jar_path} {steam_02_input_path} {steam_02_output_path}\")\n",
    "    merge_results(steam_02_output_path)\n",
    "    return HadoopRunResult(\"Steam02\",steam_02_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d787bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steam_03(steam_02_output_path):\n",
    "    steam_03_jar_path = \"/data/master_volume/map_reduce_jars/steam_03_takeN.jar\"\n",
    "    steam_03_input_path = get_data_from_output_path(steam_02_output_path)\n",
    "    steam_03_output_path = \"/out_steam_3\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {steam_03_jar_path} {steam_03_input_path} {steam_03_output_path}\")\n",
    "    merge_results(steam_03_output_path)\n",
    "    return HadoopRunResult(\"Steam03\",steam_03_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee6e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steam_04(steam_03_output_path):\n",
    "    steam_04_jar_path = \"/data/master_volume/map_reduce_jars/steam_04_fetch.jar\"\n",
    "    steam_04_input_path = get_data_from_output_path(steam_03_output_path)\n",
    "    steam_04_output_path = \"/out_steam_4\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {steam_04_jar_path} {steam_04_input_path} {steam_04_output_path}\")\n",
    "    merge_results(steam_04_output_path)\n",
    "    return HadoopRunResult(\"Steam04\",steam_04_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53c7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_steam_05(steam_04_output_path, covid_02_output_path):\n",
    "    steam_05_jar_path = \"/data/master_volume/map_reduce_jars/steam_05_merge_time.jar\"\n",
    "    steam_05_input_path = get_data_from_output_path(steam_04_output_path)\n",
    "    steam_05_input_path2 = get_data_from_output_path(covid_02_output_path)\n",
    "    steam_05_output_path = \"/out_steam_5\" + str(uuid.uuid4())\n",
    "    res = run_in_master(f\"yarn jar {steam_05_jar_path} {steam_05_input_path} {steam_05_input_path2} {steam_05_output_path}\")\n",
    "    merge_results(steam_05_output_path)\n",
    "    return HadoopRunResult(\"Steam05\",steam_05_output_path, res[0], res[1], get_elapsed_time(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbfbe733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(repeat_count: int):\n",
    "    STEP_COUNT = repeat_count\n",
    "    covid_01 = MultiRunResult.fromResults(run_n(run_covid_01, STEP_COUNT))\n",
    "    covid_02 = MultiRunResult.fromResults(run_n(lambda: run_covid_02(covid_01.output_path), STEP_COUNT))\n",
    "    covid_03 = MultiRunResult.fromResults(run_n(lambda: run_covid_03(covid_01.output_path), STEP_COUNT))\n",
    "    steam_01 = MultiRunResult.fromResults(run_n(run_steam_01, STEP_COUNT))\n",
    "    steam_02 = MultiRunResult.fromResults(run_n(lambda: run_steam_02(steam_01.output_path), STEP_COUNT))\n",
    "    steam_03 = MultiRunResult.fromResults(run_n(lambda: run_steam_03(steam_02.output_path), STEP_COUNT))\n",
    "    steam_04 = MultiRunResult.fromResults(run_n(lambda: run_steam_04(steam_03.output_path), STEP_COUNT))\n",
    "    steam_05 = MultiRunResult.fromResults(run_n(lambda: run_steam_05(steam_04.output_path, covid_02.output_path), STEP_COUNT))\n",
    "    return [covid_01, covid_02, covid_03, steam_01, steam_02, steam_03, steam_04, steam_05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d0b74",
   "metadata": {},
   "source": [
    "## 1 replika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab493392",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_in_master(\"hdfs dfs -setrep -R 1 /\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb22581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_0 (ms)</th>\n",
       "      <th>run_1 (ms)</th>\n",
       "      <th>run_2 (ms)</th>\n",
       "      <th>average (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Covid01</th>\n",
       "      <td>123710.0</td>\n",
       "      <td>121586.0</td>\n",
       "      <td>123814.0</td>\n",
       "      <td>123036.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covid02</th>\n",
       "      <td>11806.0</td>\n",
       "      <td>12135.0</td>\n",
       "      <td>12501.0</td>\n",
       "      <td>12147.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covid03</th>\n",
       "      <td>28731.0</td>\n",
       "      <td>28818.0</td>\n",
       "      <td>29110.0</td>\n",
       "      <td>28886.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam01</th>\n",
       "      <td>65277.0</td>\n",
       "      <td>66152.0</td>\n",
       "      <td>66417.0</td>\n",
       "      <td>65948.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam02</th>\n",
       "      <td>11623.0</td>\n",
       "      <td>10408.0</td>\n",
       "      <td>11282.0</td>\n",
       "      <td>11104.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam03</th>\n",
       "      <td>10973.0</td>\n",
       "      <td>10791.0</td>\n",
       "      <td>10528.0</td>\n",
       "      <td>10764.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam04</th>\n",
       "      <td>57799.0</td>\n",
       "      <td>56585.0</td>\n",
       "      <td>58850.0</td>\n",
       "      <td>57744.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam05</th>\n",
       "      <td>12166.0</td>\n",
       "      <td>12602.0</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>12289.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         run_0 (ms)  run_1 (ms)  run_2 (ms)   average (ms)\n",
       "Covid01    123710.0    121586.0    123814.0  123036.666667\n",
       "Covid02     11806.0     12135.0     12501.0   12147.333333\n",
       "Covid03     28731.0     28818.0     29110.0   28886.333333\n",
       "Steam01     65277.0     66152.0     66417.0   65948.666667\n",
       "Steam02     11623.0     10408.0     11282.0   11104.333333\n",
       "Steam03     10973.0     10791.0     10528.0   10764.000000\n",
       "Steam04     57799.0     56585.0     58850.0   57744.666667\n",
       "Steam05     12166.0     12602.0     12100.0   12289.333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_result = run_pipeline(3)\n",
    "convert_results(pipeline_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603b48e",
   "metadata": {},
   "source": [
    "## 3 repliki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4c0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_in_master(\"hdfs dfs -setrep -R 3 /\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f827650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_0 (ms)</th>\n",
       "      <th>run_1 (ms)</th>\n",
       "      <th>run_2 (ms)</th>\n",
       "      <th>average (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Covid01</th>\n",
       "      <td>121820.0</td>\n",
       "      <td>122696.0</td>\n",
       "      <td>123441.0</td>\n",
       "      <td>122652.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covid02</th>\n",
       "      <td>12502.0</td>\n",
       "      <td>11942.0</td>\n",
       "      <td>12286.0</td>\n",
       "      <td>12243.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Covid03</th>\n",
       "      <td>29490.0</td>\n",
       "      <td>27579.0</td>\n",
       "      <td>28847.0</td>\n",
       "      <td>28638.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam01</th>\n",
       "      <td>67123.0</td>\n",
       "      <td>68519.0</td>\n",
       "      <td>66975.0</td>\n",
       "      <td>67539.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam02</th>\n",
       "      <td>11175.0</td>\n",
       "      <td>11075.0</td>\n",
       "      <td>12128.0</td>\n",
       "      <td>11459.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam03</th>\n",
       "      <td>10801.0</td>\n",
       "      <td>10729.0</td>\n",
       "      <td>10231.0</td>\n",
       "      <td>10587.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam04</th>\n",
       "      <td>58301.0</td>\n",
       "      <td>58608.0</td>\n",
       "      <td>57843.0</td>\n",
       "      <td>58250.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steam05</th>\n",
       "      <td>12762.0</td>\n",
       "      <td>12060.0</td>\n",
       "      <td>12513.0</td>\n",
       "      <td>12445.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         run_0 (ms)  run_1 (ms)  run_2 (ms)   average (ms)\n",
       "Covid01    121820.0    122696.0    123441.0  122652.333333\n",
       "Covid02     12502.0     11942.0     12286.0   12243.333333\n",
       "Covid03     29490.0     27579.0     28847.0   28638.666667\n",
       "Steam01     67123.0     68519.0     66975.0   67539.000000\n",
       "Steam02     11175.0     11075.0     12128.0   11459.333333\n",
       "Steam03     10801.0     10729.0     10231.0   10587.000000\n",
       "Steam04     58301.0     58608.0     57843.0   58250.666667\n",
       "Steam05     12762.0     12060.0     12513.0   12445.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_result = run_pipeline(3)\n",
    "convert_results(pipeline_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
